{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"lab4_text_classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hExKCzh6doIW"},"source":["# Lab 4 - Neural Network Classifier Using Simple Word Embeddings\n","\n","\n","\n","---\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HixoFOoCIJ7V"},"source":["In this session, we demonstrate how to solve a text classification task using simple \n","feedforward neural network classifier. We will use IMDB Large Movie Review Dataset to train a binary classification model, able to predict whether a review is positive or negative. First, our network takes one-hot word vectors as input, averages them to make one vector and trains a \n","fully-connected layer to predict the output. In the second part, we replace the one-hot vectors with the word embeddings and add a layer to see how much that improves the performance.\n","\n","We are going to use Keras Sequential API in this session. The Sequential API allows you to make models layer-by-layer. But it is not straightforward to define models where layers connect to more than just the previous and next layers. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m8fpBfhBpupy","outputId":"53eb26fd-a00c-4685-ba66-e77fe32fe94a","executionInfo":{"status":"ok","timestamp":1583100569204,"user_tz":0,"elapsed":1669,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import keras\n","import numpy as np\n","from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n","from keras import backend as K\n","from keras.models import Sequential\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cqvPQvgvPv1W"},"source":["### Downloading data"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EundMtGPpCdf"},"source":["The dataset we will be using is the IMDB Large Movie Review Dataset, which consists of 50000 labeled movie reviews. These are split into 25,000 reviews for training and 25,000 reviews for testing. The  dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy. The data is preprocessed. For text classification, it is ususal to limit the size of the vocabulary to stop the dataset from becoming too sparse, creating possible overfitting. We keep the top 10,000 most frequently occurring words in the training data.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NyuSzkafqNca","outputId":"825a7137-9d3e-4be2-8cdc-73f9d4b11ea4","executionInfo":{"status":"ok","timestamp":1583100573644,"user_tz":0,"elapsed":6089,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["imdb = keras.datasets.imdb\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6U4iCV9-rmay"},"source":["We now can start playing around with the data, letâ€™s first see the length:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h-gjWRAuqg5s","outputId":"2b3a3253-8c7e-4524-bb57-aa2116a70b4f","executionInfo":{"status":"ok","timestamp":1583100573646,"user_tz":0,"elapsed":6079,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Training entries: {}, labels: {}\".format(len(X_train), len(y_train)))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Training entries: 25000, labels: 25000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MTRZrpcyr-4x"},"source":["The  reviews have been converted to integers and each integer represents a  word in a dictionary. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"79Ev72Kgq4XL","outputId":"4ad4e244-0708-46d9-b48e-015dc720b430","executionInfo":{"status":"ok","timestamp":1583100573649,"user_tz":0,"elapsed":6072,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":[" X_train[0]"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1,\n"," 14,\n"," 22,\n"," 16,\n"," 43,\n"," 530,\n"," 973,\n"," 1622,\n"," 1385,\n"," 65,\n"," 458,\n"," 4468,\n"," 66,\n"," 3941,\n"," 4,\n"," 173,\n"," 36,\n"," 256,\n"," 5,\n"," 25,\n"," 100,\n"," 43,\n"," 838,\n"," 112,\n"," 50,\n"," 670,\n"," 2,\n"," 9,\n"," 35,\n"," 480,\n"," 284,\n"," 5,\n"," 150,\n"," 4,\n"," 172,\n"," 112,\n"," 167,\n"," 2,\n"," 336,\n"," 385,\n"," 39,\n"," 4,\n"," 172,\n"," 4536,\n"," 1111,\n"," 17,\n"," 546,\n"," 38,\n"," 13,\n"," 447,\n"," 4,\n"," 192,\n"," 50,\n"," 16,\n"," 6,\n"," 147,\n"," 2025,\n"," 19,\n"," 14,\n"," 22,\n"," 4,\n"," 1920,\n"," 4613,\n"," 469,\n"," 4,\n"," 22,\n"," 71,\n"," 87,\n"," 12,\n"," 16,\n"," 43,\n"," 530,\n"," 38,\n"," 76,\n"," 15,\n"," 13,\n"," 1247,\n"," 4,\n"," 22,\n"," 17,\n"," 515,\n"," 17,\n"," 12,\n"," 16,\n"," 626,\n"," 18,\n"," 2,\n"," 5,\n"," 62,\n"," 386,\n"," 12,\n"," 8,\n"," 316,\n"," 8,\n"," 106,\n"," 5,\n"," 4,\n"," 2223,\n"," 5244,\n"," 16,\n"," 480,\n"," 66,\n"," 3785,\n"," 33,\n"," 4,\n"," 130,\n"," 12,\n"," 16,\n"," 38,\n"," 619,\n"," 5,\n"," 25,\n"," 124,\n"," 51,\n"," 36,\n"," 135,\n"," 48,\n"," 25,\n"," 1415,\n"," 33,\n"," 6,\n"," 22,\n"," 12,\n"," 215,\n"," 28,\n"," 77,\n"," 52,\n"," 5,\n"," 14,\n"," 407,\n"," 16,\n"," 82,\n"," 2,\n"," 8,\n"," 4,\n"," 107,\n"," 117,\n"," 5952,\n"," 15,\n"," 256,\n"," 4,\n"," 2,\n"," 7,\n"," 3766,\n"," 5,\n"," 723,\n"," 36,\n"," 71,\n"," 43,\n"," 530,\n"," 476,\n"," 26,\n"," 400,\n"," 317,\n"," 46,\n"," 7,\n"," 4,\n"," 2,\n"," 1029,\n"," 13,\n"," 104,\n"," 88,\n"," 4,\n"," 381,\n"," 15,\n"," 297,\n"," 98,\n"," 32,\n"," 2071,\n"," 56,\n"," 26,\n"," 141,\n"," 6,\n"," 194,\n"," 7486,\n"," 18,\n"," 4,\n"," 226,\n"," 22,\n"," 21,\n"," 134,\n"," 476,\n"," 26,\n"," 480,\n"," 5,\n"," 144,\n"," 30,\n"," 5535,\n"," 18,\n"," 51,\n"," 36,\n"," 28,\n"," 224,\n"," 92,\n"," 25,\n"," 104,\n"," 4,\n"," 226,\n"," 65,\n"," 16,\n"," 38,\n"," 1334,\n"," 88,\n"," 12,\n"," 16,\n"," 283,\n"," 5,\n"," 16,\n"," 4472,\n"," 113,\n"," 103,\n"," 32,\n"," 15,\n"," 16,\n"," 5345,\n"," 19,\n"," 178,\n"," 32]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Tvuu4KhStqei"},"source":["We can convert integers back to words by querying a dictionary object that contains the integer to string mapping:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gMCH1OoDrSNR","outputId":"13437e11-75cb-4177-fea2-d940d223a02b","executionInfo":{"status":"ok","timestamp":1583100574085,"user_tz":0,"elapsed":6499,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\n","word_index = imdb.get_word_index()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n","1646592/1641221 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5IreFXgruZot"},"source":["Index 1 represents the beginning of the sentence and the index 2 is assigned to all unknown tokens. Index 0 will be used for padding."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"abIb7Fe5u3GQ","colab":{}},"source":["\n","word_index = {k:(v+3) for k,v in word_index.items()}\n","word_index[\"<PAD>\"] = 0\n","word_index[\"<START>\"] = 1\n","word_index[\"<UNK>\"] = 2  \n","word_index[\"<UNUSED>\"] = 3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9TnnSuspvC5b"},"source":["To reverse key and values in a dictionary:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nKOiVVXQu-_I","colab":{}},"source":["reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZmTJEm8xvUvW"},"source":["To view a word:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SqN5jgVKvJJZ","outputId":"d24687b4-a2de-4f2b-9d12-735ceeefde9e","executionInfo":{"status":"ok","timestamp":1583100574090,"user_tz":0,"elapsed":6491,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["reverse_word_index[285]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'everything'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q6QjrzgVvrYn"},"source":["And to recreate the whole sentence from our training data we define decode_review:\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wvrKeMgxvWlv","colab":{}},"source":["def decode_review(text):\n","    return ' '.join([reverse_word_index.get(i, '?') for i in text])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Sxg4YA_NvdRg","outputId":"7af47222-f920-4512-fe51-de5202c6fc16","executionInfo":{"status":"ok","timestamp":1583100574092,"user_tz":0,"elapsed":6482,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["decode_review(X_train[10])"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<START> french horror cinema has seen something of a revival over the last couple of years with great films such as inside and <UNK> romance <UNK> on to the scene <UNK> <UNK> the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made <UNK> was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is <UNK> by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named <UNK> sent to prison for fraud he is put in a cell with three others the quietly insane <UNK> body building <UNK> marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old <UNK> after <UNK> part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that <UNK> makes the best of it's <UNK> as despite it's <UNK> the film never actually feels restrained and manages to flow well throughout director eric <UNK> provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell <UNK> that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really <UNK> people and this film proves that as the director <UNK> that we can never really be sure of exactly what is round the corner and this helps to ensure that <UNK> actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall <UNK> is a truly great horror film and one of the best of the decade highly recommended viewing\""]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"c8gIzXncfaJK"},"source":["### Creating One-hot word vectors"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B9W4yb3rv_E0"},"source":["It is  common to use one-hot representation as input in Natural Language Processing tasks. In Keras, the Embedding layer takes an index as an input and convert it to one-hot vector with the length of the vocabulary size. Then multiplies these vectors by a normal weight matrix. But there is no way to only get a one-hot vector as the output of a layer in Keras. To solve this we use Lambda() layer and a function that creates the one-hot layer. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RPO_pK9zH4C5","colab":{}},"source":["def OneHot(input_dim=1, input_length=1000):\n","    \n","    if input_dim is None or input_length is None:\n","        raise TypeError(\"input_dim or input_length is not set\")\n","\n","    \n","    def _one_hot(x, num_classes):\n","        return K.one_hot(K.cast(x, 'uint8'),\n","                          num_classes=num_classes)\n","\n","    return Lambda(_one_hot,\n","                  arguments={'num_classes': input_dim},\n","                  input_shape=(input_length,))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"364d3MAw0ez9"},"source":["input_dim refers to the length of the one-hot vector and input_length refers to the length of the input sequence. Since the input to K.one_hot should be an integer tensor, we cast x to one (Keras passes around float tensors by default).\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VHz76GNA2M4r"},"source":[" Each text sequence has in most cases different length of words. Here, we fill sequences with a pad token (0) to fit the size. This special tokens is then masked not to be accounted in averaging, loss calculation etc. We set the maximum length to 256."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9G_o7PsvgSFt"},"source":["### Preparing input data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jiFn7sd_wF5j","colab":{}},"source":["VOCAB_SIZE = 10000\n","MAX_SEQUENCE_LENGTH = 256\n","\n","X_train_enc = keras.preprocessing.sequence.pad_sequences(X_train,\n","                                                        value=word_index[\"<PAD>\"],\n","                                                        padding='post',\n","                                                        maxlen=256)\n","\n","X_test_enc = keras.preprocessing.sequence.pad_sequences(X_test,\n","                                                       value=word_index[\"<PAD>\"],\n","                                                       padding='post',\n","                                                       maxlen=256)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kcjFH1wKF_7d"},"source":["And to view a padded review:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zwH4dcfW_a18","outputId":"8e53f7c2-b01d-4ba9-932d-86a90bd95513","executionInfo":{"status":"ok","timestamp":1583100575116,"user_tz":0,"elapsed":7492,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["print(X_train_enc[1])\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[   1  194 1153  194 8255   78  228    5    6 1463 4369 5012  134   26\n","    4  715    8  118 1634   14  394   20   13  119  954  189  102    5\n","  207  110 3103   21   14   69  188    8   30   23    7    4  249  126\n","   93    4  114    9 2300 1523    5  647    4  116    9   35 8163    4\n","  229    9  340 1322    4  118    9    4  130 4901   19    4 1002    5\n","   89   29  952   46   37    4  455    9   45   43   38 1543 1905  398\n","    4 1649   26 6853    5  163   11 3215    2    4 1153    9  194  775\n","    7 8255    2  349 2637  148  605    2 8003   15  123  125   68    2\n"," 6853   15  349  165 4362   98    5    4  228    9   43    2 1157   15\n","  299  120    5  120  174   11  220  175  136   50    9 4373  228 8255\n","    5    2  656  245 2350    5    4 9837  131  152  491   18    2   32\n"," 7464 1212   14    9    6  371   78   22  625   64 1382    9    8  168\n","  145   23    4 1690   15   16    4 1355    5   28    6   52  154  462\n","   33   89   78  285   16  145   95    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F1zcxFwNGepA"},"source":["Now we want to build the neural network model. We  are going to have a hidden layer with 16 hidden units. \n","\n","First, we want to transform each index to an embedded vector and then average all vectors to a single one. It has been showed that unweighted average of word vectors outperforms many complicated networks that model semantic and syntactic compositionality. As an example you can take a look at this: (http://anthology.aclweb.org/P/P15/P15-1162.pdf)\n","\n","To average we need to ignore padded zeros:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Yi04MLIvJOGZ","colab":{}},"source":["class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n","    def call(self, x, mask=None):\n","        if mask != None:\n","            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n","        else:\n","            return super().call(x)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"whgIIB5ggjna"},"source":["### Neural Network model using one-hot vectors"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jlOLnlnSJgrU"},"source":["The first layer is an one-hot layer. The second layer is to compute average on all word vectors in a sentence without considering padding. The  output vector is piped through a fully-connected layer. The last layer is connected with a single output node with the sigmoid activation function. The final value is a float between 0 and 1. \n","The vocabulary count of the movie reviews (10000) is used as the input shape. At the end we visualize the model summary."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_Pn83gBbxiK7","outputId":"6f9f4388-bb32-454a-c605-6a6f2665568e","executionInfo":{"status":"ok","timestamp":1583100575119,"user_tz":0,"elapsed":7484,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["# put your code here\n","  model = Sequential()\n","  model.add(OneHot(VOCAB_SIZE, MAX_SEQUENCE_LENGTH))\n","  model.add(GlobalAveragePooling1DMasked())\n","  model.add(Dense(16, activation = 'relu'))\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  model.summary()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lambda_1 (Lambda)            (None, 256, 10000)        0         \n","_________________________________________________________________\n","global_average_pooling1d_mas (None, 10000)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 16)                160016    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 17        \n","=================================================================\n","Total params: 160,033\n","Trainable params: 160,033\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_Mz96xpCgvTj"},"source":["### Training the model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F3HbW_IKLqwT"},"source":["To compile the model we need a loss function and an optimizer. We use binary_crossentropy loss function which is just a special case of categorical cross entropy. We also use Adam optimizer that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. You can read more about it here:\n","(https://arxiv.org/abs/1412.6980v8\n",")\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qh1PWTNMxjUw","outputId":"2cdba22f-1a4f-45be-f88d-2aba6b071cbc","executionInfo":{"status":"ok","timestamp":1583100575120,"user_tz":0,"elapsed":7475,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["model.compile(optimizer='adam',\n","loss='binary_crossentropy',\n","metrics=['accuracy'])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E1jwQQqCN5Ia"},"source":["When training, we want to check the accuracy of the model on data it hasn't seen before. So we create a validation set:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f5lAqzQlxjSM","colab":{}},"source":["X_val = np.array(X_train_enc[:10000])\n","partial_X_train = np.array(X_train_enc[10000:])\n","\n","y_val = np.array(y_train[:10000])\n","partial_y_train = np.array(y_train[10000:])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E8Kpo5G3OJEY"},"source":["Then we start to train the model for 40 epochs in mini-batches of 512 samples and monitor the model's loss and accuracy on the validation set."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"99_z39KAxjPi","outputId":"4973fd45-708d-42a2-ffa5-4c83d4d55861","executionInfo":{"status":"ok","timestamp":1583100718225,"user_tz":0,"elapsed":150570,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["  history = model.fit(partial_X_train,\n","                    partial_y_train,\n","                    epochs=40,\n","                    batch_size=512,\n","                    validation_data=(X_val, y_val),\n","                    verbose=1)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 15000 samples, validate on 10000 samples\n","Epoch 1/40\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","15000/15000 [==============================] - 13s 867us/step - loss: 0.6926 - acc: 0.5607 - val_loss: 0.6919 - val_acc: 0.5245\n","Epoch 2/40\n","15000/15000 [==============================] - 3s 214us/step - loss: 0.6908 - acc: 0.6183 - val_loss: 0.6899 - val_acc: 0.6505\n","Epoch 3/40\n","15000/15000 [==============================] - 3s 214us/step - loss: 0.6884 - acc: 0.6611 - val_loss: 0.6873 - val_acc: 0.6670\n","Epoch 4/40\n","15000/15000 [==============================] - 3s 215us/step - loss: 0.6855 - acc: 0.6637 - val_loss: 0.6843 - val_acc: 0.6639\n","Epoch 5/40\n","15000/15000 [==============================] - 3s 215us/step - loss: 0.6821 - acc: 0.6387 - val_loss: 0.6811 - val_acc: 0.6639\n","Epoch 6/40\n","15000/15000 [==============================] - 3s 216us/step - loss: 0.6782 - acc: 0.6745 - val_loss: 0.6770 - val_acc: 0.6724\n","Epoch 7/40\n","15000/15000 [==============================] - 3s 217us/step - loss: 0.6738 - acc: 0.6826 - val_loss: 0.6727 - val_acc: 0.6768\n","Epoch 8/40\n","15000/15000 [==============================] - 3s 218us/step - loss: 0.6690 - acc: 0.6817 - val_loss: 0.6683 - val_acc: 0.6779\n","Epoch 9/40\n","15000/15000 [==============================] - 3s 217us/step - loss: 0.6639 - acc: 0.6854 - val_loss: 0.6633 - val_acc: 0.6830\n","Epoch 10/40\n","15000/15000 [==============================] - 3s 219us/step - loss: 0.6585 - acc: 0.6876 - val_loss: 0.6579 - val_acc: 0.6848\n","Epoch 11/40\n","15000/15000 [==============================] - 3s 219us/step - loss: 0.6529 - acc: 0.6897 - val_loss: 0.6528 - val_acc: 0.6871\n","Epoch 12/40\n","15000/15000 [==============================] - 3s 219us/step - loss: 0.6473 - acc: 0.6926 - val_loss: 0.6474 - val_acc: 0.6897\n","Epoch 13/40\n","15000/15000 [==============================] - 3s 221us/step - loss: 0.6416 - acc: 0.6958 - val_loss: 0.6420 - val_acc: 0.6907\n","Epoch 14/40\n","15000/15000 [==============================] - 3s 220us/step - loss: 0.6362 - acc: 0.6985 - val_loss: 0.6367 - val_acc: 0.6899\n","Epoch 15/40\n","15000/15000 [==============================] - 3s 221us/step - loss: 0.6303 - acc: 0.6996 - val_loss: 0.6320 - val_acc: 0.6991\n","Epoch 16/40\n","15000/15000 [==============================] - 3s 222us/step - loss: 0.6249 - acc: 0.7034 - val_loss: 0.6264 - val_acc: 0.6975\n","Epoch 17/40\n","15000/15000 [==============================] - 3s 223us/step - loss: 0.6195 - acc: 0.7026 - val_loss: 0.6218 - val_acc: 0.7037\n","Epoch 18/40\n","15000/15000 [==============================] - 3s 222us/step - loss: 0.6141 - acc: 0.7081 - val_loss: 0.6166 - val_acc: 0.6969\n","Epoch 19/40\n","15000/15000 [==============================] - 3s 223us/step - loss: 0.6092 - acc: 0.7111 - val_loss: 0.6116 - val_acc: 0.7052\n","Epoch 20/40\n","15000/15000 [==============================] - 3s 224us/step - loss: 0.6041 - acc: 0.7131 - val_loss: 0.6072 - val_acc: 0.7099\n","Epoch 21/40\n","15000/15000 [==============================] - 3s 223us/step - loss: 0.5993 - acc: 0.7174 - val_loss: 0.6024 - val_acc: 0.7094\n","Epoch 22/40\n","15000/15000 [==============================] - 3s 224us/step - loss: 0.5946 - acc: 0.7177 - val_loss: 0.5980 - val_acc: 0.7088\n","Epoch 23/40\n","15000/15000 [==============================] - 3s 225us/step - loss: 0.5900 - acc: 0.7177 - val_loss: 0.5937 - val_acc: 0.7152\n","Epoch 24/40\n","15000/15000 [==============================] - 3s 224us/step - loss: 0.5854 - acc: 0.7217 - val_loss: 0.5909 - val_acc: 0.7177\n","Epoch 25/40\n","15000/15000 [==============================] - 3s 226us/step - loss: 0.5814 - acc: 0.7234 - val_loss: 0.5868 - val_acc: 0.7192\n","Epoch 26/40\n","15000/15000 [==============================] - 3s 226us/step - loss: 0.5774 - acc: 0.7263 - val_loss: 0.5829 - val_acc: 0.7210\n","Epoch 27/40\n","15000/15000 [==============================] - 3s 226us/step - loss: 0.5735 - acc: 0.7283 - val_loss: 0.5784 - val_acc: 0.7245\n","Epoch 28/40\n","15000/15000 [==============================] - 3s 226us/step - loss: 0.5699 - acc: 0.7285 - val_loss: 0.5752 - val_acc: 0.7257\n","Epoch 29/40\n","15000/15000 [==============================] - 3s 226us/step - loss: 0.5664 - acc: 0.7304 - val_loss: 0.5714 - val_acc: 0.7269\n","Epoch 30/40\n","15000/15000 [==============================] - 3s 226us/step - loss: 0.5630 - acc: 0.7335 - val_loss: 0.5682 - val_acc: 0.7282\n","Epoch 31/40\n","15000/15000 [==============================] - 3s 225us/step - loss: 0.5595 - acc: 0.7357 - val_loss: 0.5652 - val_acc: 0.7296\n","Epoch 32/40\n","15000/15000 [==============================] - 3s 224us/step - loss: 0.5564 - acc: 0.7374 - val_loss: 0.5626 - val_acc: 0.7309\n","Epoch 33/40\n","15000/15000 [==============================] - 3s 225us/step - loss: 0.5538 - acc: 0.7376 - val_loss: 0.5596 - val_acc: 0.7318\n","Epoch 34/40\n","15000/15000 [==============================] - 3s 225us/step - loss: 0.5513 - acc: 0.7386 - val_loss: 0.5571 - val_acc: 0.7320\n","Epoch 35/40\n","15000/15000 [==============================] - 3s 225us/step - loss: 0.5486 - acc: 0.7400 - val_loss: 0.5548 - val_acc: 0.7348\n","Epoch 36/40\n","15000/15000 [==============================] - 3s 223us/step - loss: 0.5458 - acc: 0.7407 - val_loss: 0.5524 - val_acc: 0.7362\n","Epoch 37/40\n","15000/15000 [==============================] - 3s 223us/step - loss: 0.5433 - acc: 0.7433 - val_loss: 0.5501 - val_acc: 0.7377\n","Epoch 38/40\n","15000/15000 [==============================] - 3s 224us/step - loss: 0.5410 - acc: 0.7435 - val_loss: 0.5486 - val_acc: 0.7373\n","Epoch 39/40\n","15000/15000 [==============================] - 3s 223us/step - loss: 0.5392 - acc: 0.7447 - val_loss: 0.5472 - val_acc: 0.7366\n","Epoch 40/40\n","15000/15000 [==============================] - 3s 223us/step - loss: 0.5372 - acc: 0.7451 - val_loss: 0.5445 - val_acc: 0.7400\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"i_9a_rybhG5J"},"source":["### Evaluating the model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EYLH8kOgOo9W"},"source":["To evaulate the model on test data:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CFMt2Q7b3taP","outputId":"f153cb45-96ae-4924-f193-25bfc29d40ca","executionInfo":{"status":"ok","timestamp":1583100721881,"user_tz":0,"elapsed":154217,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["results = model.evaluate(X_test_enc, y_test)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["25000/25000 [==============================] - 4s 150us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9RrKiPHcAmQU","outputId":"66245ddf-be59-4a6b-8ba5-e00fae37359e","executionInfo":{"status":"ok","timestamp":1583100721884,"user_tz":0,"elapsed":154212,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(results)\n","# loss, accuracy "],"execution_count":20,"outputs":[{"output_type":"stream","text":["[0.5440368103027344, 0.73972]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pW7IpHxMO6qp"},"source":["Our first model accuracy using one-hot vectors is \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OwZk_yoWhPJB"},"source":["### Plotting the accuracy graph"]},{"cell_type":"markdown","metadata":{"id":"rYSJp52YI32s","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JIDPH1J7PMzN"},"source":["To plot a graph of accuracy and loss over time we can use Matplotlib:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LS9k2vvSAqB7","outputId":"bdf39647-ba1c-4be1-a36d-69e71795ff31","executionInfo":{"status":"ok","timestamp":1583100722169,"user_tz":0,"elapsed":154487,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["import matplotlib.pyplot as plt\n","\n","history_dict = history.history\n","\n","acc = history_dict['acc']\n","val_acc = history_dict['val_acc']\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSf0/xAz0vcSkzi8AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"a7OwOQw4h8RX"},"source":["### Neural Network model using word embeddings"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"l-QzOMO_P4jc"},"source":["Now instead of one-hot vectors, we want to use embedding. We change our first layer in model1 to an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MFrCsL-NBFVL","outputId":"40ee9e29-7f86-4b13-8826-d93f98f983fa","executionInfo":{"status":"ok","timestamp":1583100733448,"user_tz":0,"elapsed":165757,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["VOCAB_SIZE= 10000\n","\n","# put the code here\n","model2 = Sequential()\n","model2.add(Embedding(VOCAB_SIZE, 100))\n","model2.add(GlobalAveragePooling1DMasked())\n","model2.add(Dense(16, activation = 'relu'))\n","model2.add(Dense(1, activation = 'sigmoid'))\n","model2.summary()\n","\n","model2.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","X_val = np.array(X_train_enc[:10000])\n","partial_X_train = np.array(X_train_enc[10000:])\n","\n","history2 = model2.fit(partial_X_train,\n","                    partial_y_train,\n","                    epochs=40,\n","                    batch_size=512,\n","                    validation_data=(X_val, y_val),\n","                    verbose=1)\n","\n","results = model2.evaluate(X_test_enc, y_test)\n","print(results)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, None, 100)         1000000   \n","_________________________________________________________________\n","global_average_pooling1d_mas (None, 100)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 16)                1616      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 17        \n","=================================================================\n","Total params: 1,001,633\n","Trainable params: 1,001,633\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 15000 samples, validate on 10000 samples\n","Epoch 1/40\n","15000/15000 [==============================] - 0s 33us/step - loss: 0.6896 - acc: 0.6440 - val_loss: 0.6830 - val_acc: 0.7374\n","Epoch 2/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.6675 - acc: 0.7432 - val_loss: 0.6482 - val_acc: 0.7347\n","Epoch 3/40\n","15000/15000 [==============================] - 0s 14us/step - loss: 0.6119 - acc: 0.7821 - val_loss: 0.5791 - val_acc: 0.7862\n","Epoch 4/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.5257 - acc: 0.8177 - val_loss: 0.4944 - val_acc: 0.8219\n","Epoch 5/40\n","15000/15000 [==============================] - 0s 17us/step - loss: 0.4370 - acc: 0.8522 - val_loss: 0.4220 - val_acc: 0.8455\n","Epoch 6/40\n","15000/15000 [==============================] - 0s 17us/step - loss: 0.3671 - acc: 0.8749 - val_loss: 0.3730 - val_acc: 0.8601\n","Epoch 7/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.3168 - acc: 0.8892 - val_loss: 0.3424 - val_acc: 0.8675\n","Epoch 8/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.2799 - acc: 0.9011 - val_loss: 0.3227 - val_acc: 0.8700\n","Epoch 9/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.2502 - acc: 0.9123 - val_loss: 0.3094 - val_acc: 0.8755\n","Epoch 10/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.2269 - acc: 0.9194 - val_loss: 0.2978 - val_acc: 0.8818\n","Epoch 11/40\n","15000/15000 [==============================] - 0s 17us/step - loss: 0.2063 - acc: 0.9287 - val_loss: 0.2918 - val_acc: 0.8819\n","Epoch 12/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.1886 - acc: 0.9365 - val_loss: 0.2884 - val_acc: 0.8849\n","Epoch 13/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.1735 - acc: 0.9435 - val_loss: 0.2872 - val_acc: 0.8838\n","Epoch 14/40\n","15000/15000 [==============================] - 0s 17us/step - loss: 0.1600 - acc: 0.9487 - val_loss: 0.2866 - val_acc: 0.8849\n","Epoch 15/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.1476 - acc: 0.9544 - val_loss: 0.2906 - val_acc: 0.8843\n","Epoch 16/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.1378 - acc: 0.9585 - val_loss: 0.2901 - val_acc: 0.8854\n","Epoch 17/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.1263 - acc: 0.9643 - val_loss: 0.2926 - val_acc: 0.8841\n","Epoch 18/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.1177 - acc: 0.9672 - val_loss: 0.2967 - val_acc: 0.8847\n","Epoch 19/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.1088 - acc: 0.9697 - val_loss: 0.3015 - val_acc: 0.8831\n","Epoch 20/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.1011 - acc: 0.9727 - val_loss: 0.3119 - val_acc: 0.8796\n","Epoch 21/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.0947 - acc: 0.9754 - val_loss: 0.3135 - val_acc: 0.8814\n","Epoch 22/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.0875 - acc: 0.9785 - val_loss: 0.3210 - val_acc: 0.8799\n","Epoch 23/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.0817 - acc: 0.9801 - val_loss: 0.3276 - val_acc: 0.8790\n","Epoch 24/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.0759 - acc: 0.9823 - val_loss: 0.3344 - val_acc: 0.8788\n","Epoch 25/40\n","15000/15000 [==============================] - 0s 17us/step - loss: 0.0702 - acc: 0.9846 - val_loss: 0.3412 - val_acc: 0.8785\n","Epoch 26/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.0653 - acc: 0.9866 - val_loss: 0.3505 - val_acc: 0.8761\n","Epoch 27/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.0607 - acc: 0.9881 - val_loss: 0.3577 - val_acc: 0.8772\n","Epoch 28/40\n","15000/15000 [==============================] - 0s 19us/step - loss: 0.0567 - acc: 0.9895 - val_loss: 0.3664 - val_acc: 0.8761\n","Epoch 29/40\n","15000/15000 [==============================] - 0s 17us/step - loss: 0.0530 - acc: 0.9905 - val_loss: 0.3775 - val_acc: 0.8727\n","Epoch 30/40\n","15000/15000 [==============================] - 0s 20us/step - loss: 0.0492 - acc: 0.9914 - val_loss: 0.3833 - val_acc: 0.8745\n","Epoch 31/40\n","15000/15000 [==============================] - 0s 18us/step - loss: 0.0456 - acc: 0.9925 - val_loss: 0.3920 - val_acc: 0.8751\n","Epoch 32/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.0424 - acc: 0.9933 - val_loss: 0.4017 - val_acc: 0.8749\n","Epoch 33/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.0399 - acc: 0.9936 - val_loss: 0.4098 - val_acc: 0.8732\n","Epoch 34/40\n","15000/15000 [==============================] - 0s 14us/step - loss: 0.0368 - acc: 0.9948 - val_loss: 0.4208 - val_acc: 0.8700\n","Epoch 35/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.0343 - acc: 0.9951 - val_loss: 0.4304 - val_acc: 0.8694\n","Epoch 36/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.0319 - acc: 0.9958 - val_loss: 0.4388 - val_acc: 0.8706\n","Epoch 37/40\n","15000/15000 [==============================] - 0s 15us/step - loss: 0.0297 - acc: 0.9969 - val_loss: 0.4476 - val_acc: 0.8704\n","Epoch 38/40\n","15000/15000 [==============================] - 0s 14us/step - loss: 0.0277 - acc: 0.9965 - val_loss: 0.4575 - val_acc: 0.8684\n","Epoch 39/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.0256 - acc: 0.9974 - val_loss: 0.4669 - val_acc: 0.8676\n","Epoch 40/40\n","15000/15000 [==============================] - 0s 16us/step - loss: 0.0238 - acc: 0.9977 - val_loss: 0.4760 - val_acc: 0.8667\n","25000/25000 [==============================] - 1s 42us/step\n","[0.5077659516668319, 0.8554]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I4zIPJDcTPq3","outputId":"0919ea98-c878-42ce-b108-bcb210c50d75","executionInfo":{"status":"ok","timestamp":1583100734752,"user_tz":0,"elapsed":167052,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["results = model2.evaluate(X_test_enc, y_test)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["25000/25000 [==============================] - 1s 40us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"waS96edDTRyL","outputId":"8e21983f-0668-4671-cb1a-411888b5476b","executionInfo":{"status":"ok","timestamp":1583100734755,"user_tz":0,"elapsed":167046,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print (results)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.5077659516668319, 0.8554]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XB7aveVzTC5a","outputId":"2ad3bb82-b543-441a-fdf7-90b732e3f6ec","executionInfo":{"status":"ok","timestamp":1583100734757,"user_tz":0,"elapsed":167040,"user":{"displayName":"Vinayak Manjunath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2TC3HJCReEeIYXqoJo1HOksYAMK9Z7d8qzXJ3Z1o=s64","userId":"12254610052699171324"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["import matplotlib.pyplot as plt\n","\n","history_dict = history2.history\n","\n","acc = history_dict['acc']\n","val_acc = history_dict['val_acc']\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoIQEZGk/j+8nWZpWhP3rgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7FBpTc_rXGvQ"},"source":["The accuracy of model2 is 87%. Using Embedding layer instead of one-hot layer improved the performance."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"--020hfG6rN2"},"source":["### Using pre-trained word embeddings"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J4gBeOyi4gkM"},"source":["The Embedding layer can be used to load a pre-trained word embedding model. We are going to use GloVe embeddings, which you can read about it here (https://nlp.stanford.edu/projects/glove/). GloVe stands for \"Global Vectors for Word Representation\". It's a somewhat popular embedding technique based on factorizing a matrix of word co-occurence statistics. You can download GloVe and we can seed the Keras Embedding layer with weights from the pre-trained embedding for the words in your dataset.\n","First, we need to read GloVe and map words to GloVe:\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f_PypdqG9Iis","colab":{}},"source":["def readGloveFile(gloveFile):\n","    with open(gloveFile, 'r') as f:\n","        wordToGlove = {}  \n","        wordToIndex = {}  \n","        indexToWord = {}  \n","\n","        for line in f:\n","            record = line.strip().split()\n","            token = record[0] \n","            wordToGlove[token] = np.array(record[1:], dtype=np.float64) \n","            \n","        tokens = sorted(wordToGlove.keys())\n","        for idx, tok in enumerate(tokens):\n","            kerasIdx = idx + 1  \n","            wordToIndex[tok] = kerasIdx \n","            indexToWord[kerasIdx] = tok \n","\n","    return wordToIndex, indexToWord, wordToGlove"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZcIZ3dq59bCh"},"source":["Now, we create our pre-trained Embedding layer:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gembn7VM3ex8","colab":{}},"source":["def createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable):\n","    vocabLen = len(wordToIndex) + 1  \n","    embDim = next(iter(wordToGlove.values())).shape[0]  \n","   \n","    embeddingMatrix = np.zeros((vocabLen, embDim))  \n","    for word, index in wordToIndex.items():\n","        embeddingMatrix[index, :] = wordToGlove[word] \n","\n","    embeddingLayer = Embedding(vocabLen, embDim, embeddings_initializer=Constant(embeddingMatrix), trainable=isTrainable)\n","    return embeddingLayer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HGxciLK4-xOr"},"source":["We freeze the weights. To create the model:"]},{"cell_type":"code","metadata":{"id":"uXJ4qkEy8ySv","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PZCPUM0W_Drc","colab":{}},"source":["# put the code here\n","from keras.initializers import Constant\n","wordToIndex, indexToWord, wordToGlove = readGloveFile('drive/My Drive/GLOVE/glove.6B.300d.txt')\n","isTrainable=True\n","model3 = Sequential()\n","model3.add(createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable))\n","model3.add(GlobalAveragePooling1DMasked())\n","model3.add(Dense(16, activation= 'relu'))\n","#model3.add(Dense(1, activation= 'sigmoid'))\n","#model3.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M-bZ5SCHiIMl"},"source":["### Adding another hidden layer to the network"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZbZ6UBDfbjea"},"source":["In model3, we only add another dense layer to see if that improves the performance."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Vw0le1YjDdCa","colab":{}},"source":["# put your code here\n","# model3.add(Dense(16, activation = 'relu'))\n","model3.add(Dense(1, activation = 'sigmoid'))\n","model3.summary()\n","\n","model3.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","X_val = np.array(X_train_enc[:10000])\n","partial_X_train = np.array(X_train_enc[10000:])\n","\n","history3 = model3.fit(partial_X_train,\n","                    partial_y_train,\n","                    epochs=40,\n","                    batch_size=512,\n","                    validation_data=(X_val, y_val),\n","                    verbose=1)\n","\n","results = model3.evaluate(X_test_enc, y_test)\n","print(results)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QtsdVeW7UgCu","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","history_dict = history3.history\n","\n","acc = history_dict['acc']\n","val_acc = history_dict['val_acc']\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Kx--Ytk3ZbLo"},"source":["The accuracy of model3 with an additional layer is 85%. Adding more layers can help you to extract more features. But we can do that upto a certain extent. After some point, instead of extracting features, we tend to overfit the data. Overfitting can lead to errors in some or the other form like false positives. It is not easy to choose the number of units in a hidden layer or the number of hidden layers in a neural network. For many applications, one hidden layer is enough. As a general rule, the number of units in that hidden layer is between the number of inputs and the number of outputs.\n"," The best way to decide on the number of units and hidden layers is to try various parameters. Train several neural networks with different numbers of hidden layers and neurons, and monitor the performance of them. You will have to experiment using a series of different architectures. \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gn2GSV4ioyO2"},"source":["\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XYC6DykEox2w","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GsCJ01StlgCx"},"source":["This tutorial is substantially based on this document:\n","https://www.tensorflow.org/tutorials/keras/basic_text_classification\n","\n","To read more about Sequential APIs you can go to: https://keras.io/getting-started/sequential-model-guide/\n","\n","The one-hot word vector layer is taken from:\n","https://fdalvi.github.io/blog/2018-04-07-keras-sequential-onehot/\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jL0UovfaE9GE","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}